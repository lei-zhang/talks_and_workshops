m <- mean(x)
ymin <- m-sd(x)
ymax <- m+sd(x)
return(c(y=m,ymin=ymin,ymax=ymax))
}
pars_true_value <- matrix(rl_par, 20, 1)
pars_name  <- as.factor(c(rep('lr',10),rep('tau',10)))
df2 <- data.frame(pars_true_value=pars_true_value, pars_name=pars_name)
g2 <- ggplot(df2, aes(x=pars_name, y=pars_true_value, color = pars_name, fill=pars_name))
g2 <- g2 + geom_violin(trim=TRUE, size=2)
g2 <- g2 + stat_summary(fun.data=data_summary, geom="pointrange", color="black", size=1.5)
g2 <- g2 + scale_fill_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + scale_color_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + myconfig + theme(legend.position="none")
g2 <- g2 + labs(x = '', y = 'parameter value')
print(g2)
load('_data/rl_mp.RData')
pars_true_value <- matrix(rl_mp, 20, 1)
pars_name  <- as.factor(c(rep('lr',10),rep('tau',10)))
df2 <- data.frame(pars_true_value=pars_true_value, pars_name=pars_name)
g2 <- ggplot(df2, aes(x=pars_name, y=pars_true_value, color = pars_name, fill=pars_name))
g2 <- g2 + geom_violin(trim=TRUE, size=2)
g2 <- g2 + stat_summary(fun.data=data_summary, geom="pointrange", color="black", size=1.5)
g2 <- g2 + scale_fill_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + scale_color_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + myconfig + theme(legend.position="none")
g2 <- g2 + labs(x = '', y = 'parameter value')
print(g2)
library(ggplot2)
pars_true_value <- matrix(rl_par, 20, 1)
pars_name  <- as.factor(c(rep('lr',10),rep('tau',10)))
df2 <- data.frame(pars_true_value=pars_true_value, pars_name=pars_name)
g2 <- ggplot(df2, aes(x=pars_name, y=pars_true_value, color = pars_name, fill=pars_name))
g2 <- g2 + geom_violin(trim=TRUE, size=2)
g2 <- g2 + stat_summary(fun.data=data_summary, geom="pointrange", color="black", size=1.5)
g2 <- g2 + scale_fill_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + scale_color_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + myconfig + theme(legend.position="none")
g2 <- g2 + labs(x = '', y = 'parameter value')
print(g2)
pars_true_value <- matrix(rl_mp, 20, 1)
pars_name  <- as.factor(c(rep('lr',10),rep('tau',10)))
df2 <- data.frame(pars_true_value=pars_true_value, pars_name=pars_name)
g2 <- ggplot(df2, aes(x=pars_name, y=pars_true_value, color = pars_name, fill=pars_name))
g2 <- g2 + geom_violin(trim=TRUE, size=2)
g2 <- g2 + stat_summary(fun.data=data_summary, geom="pointrange", color="black", size=1.5)
g2 <- g2 + scale_fill_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + scale_color_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + myconfig + theme(legend.position="none")
g2 <- g2 + labs(x = '', y = 'parameter value')
print(g2)
lr = rnorm(10, 0.6, 0.12)
tau = rnorm(10, 1.5, 0.2)
rl_par = c(lr, tau)
data_summary <- function(x) {
m <- mean(x)
ymin <- m-sd(x)
ymax <- m+sd(x)
return(c(y=m,ymin=ymin,ymax=ymax))
}
pars_true_value <- matrix(rl_par, 20, 1)
pars_name  <- as.factor(c(rep('lr',10),rep('tau',10)))
df2 <- data.frame(pars_true_value=pars_true_value, pars_name=pars_name)
g2 <- ggplot(df2, aes(x=pars_name, y=pars_true_value, color = pars_name, fill=pars_name))
g2 <- g2 + geom_violin(trim=TRUE, size=2)
g2 <- g2 + stat_summary(fun.data=data_summary, geom="pointrange", color="black", size=1.5)
g2 <- g2 + scale_fill_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + scale_color_manual(values=c("#2179b5", "#c60256"))
g2 <- g2 + myconfig + theme(legend.position="none")
g2 <- g2 + labs(x = '', y = 'parameter value')
print(g2)
load('_data/rl_mp.RData')
sz <- dim(rl_mp)
rl_mp
nSubjects <- sz[1]
nTrials   <- sz[2]
nSubjects
nTrials
source('E:/teaching/BayesCog_2018/BayesCog_2018_materials/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
library(rstan)
library(ggplot2)
library(R.matlab)
multiSubj = FALSE
load('_data/rl_sp_ms.RData')
sz <- dim(rl_ms)
nSubjects <- sz[1]
nTrials   <- sz[2]
dataList <- list(nSubjects=nSubjects,
nTrials=nTrials,
choice=rl_ms[,,1],
reward=rl_ms[,,2])
rl_ms
load('_data/rl_sp_ss.RData')
rl_ss
head(rl_ss)
source('E:/teaching/BayesCog_2018/BayesCog_2018_materials/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
load('_data/rl_sp_ss.RData')
sz <- dim(rl_ss)
nTrials <- sz[1]
dataList <- list(nTrials=nTrials,
choice=rl_ss[,1],
reward=rl_ss[,2])
modelFile <- '_scripts/reinforcement_learning_sp_ss_model.stan'
nIter     <- 2000
nChains   <- 4
nWarmup   <- floor(nIter/2)
nThin     <- 1
cat("Estimating", modelFile, "model... \n")
startTime = Sys.time(); print(startTime)
cat("Calling", nChains, "simulations in Stan... \n")
fit_rl <- stan(modelFile,
data    = dataList,
chains  = nChains,
iter    = nIter,
warmup  = nWarmup,
thin    = nThin,
init    = "random",
seed    = 1450154626)
cat("Finishing", modelFile, "model simulation ... \n")
endTime = Sys.time(); print(endTime)
cat("It took",as.character.Date(endTime - startTime), "\n")
source('E:/teaching/BayesCog_2018/BayesCog_2018_materials/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
f = run_rl_sp(multiSubj = FALSE)
f = run_rl_sp(multiSubj = T)
source('E:/teaching/BayesCog_2018/BayesCog_2018_materials/06.reinforcement_learning/_scripts/reinforcement_learning_multi_parm_main_master.R')
f = run_rl_pp()
f = run_rl_mp()
rm(list=ls(all=TRUE))
source('E:/teaching/BayesCog_2018/BayesCog_2018_materials/06.reinforcement_learning/_scripts/reinforcement_learning_multi_parm_main_master.R')
f = run_rl_mp()
modelType = 'indv'
# clear workspace
library(rstan)
library(ggplot2)
library(R.matlab)
load('_data/rl_mp.RData')
sz <- dim(rl_mp)
nSubjects <- sz[1]
nTrials   <- sz[2]
dataList <- list(nSubjects=nSubjects,
nTrials=nTrials,
choice=rl_mp[,,1],
reward=rl_mp[,,2])
rstan_options(auto_write = TRUE)
options(mc.cores = 2)
rstan:::rstudio_stanc("_scripts/reinforcement_learning_mp_indv_model.stan")
rstan_options(auto_write = TRUE)
options(mc.cores = 2)
modelFile <- '_scripts/reinforcement_learning_mp_indv_model.stan'
nIter     <- 2000
nChains   <- 4
nWarmup   <- floor(nIter/2)
nThin     <- 1
cat("Estimating", modelFile, "model... \n")
startTime = Sys.time(); print(startTime)
cat("Calling", nChains, "simulations in Stan... \n")
fit_rl <- stan(modelFile,
data    = dataList,
chains  = nChains,
iter    = nIter,
warmup  = nWarmup,
thin    = nThin,
init    = "random",
control  = list(adapt_delta=0.999, max_treedepth=100),
seed    = 1450154626
)
fit_rl <- stan(modelFile,
data    = dataList,
chains  = nChains,
iter    = nIter,
warmup  = nWarmup,
thin    = nThin,
init    = "random",
#control  = list(adapt_delta=0.999, max_treedepth=100),
seed    = 1450154626
)
source('E:/teaching/BayesCog_2018/BayesCog_2018/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
fit_rl1 = run_rl_sp()
library(hBayesDM)
L = bandit2arm_delta(data = '_data/rawdata.txt', niter = 100, nwarmup = 0,ncore = 1)
L = bandit2arm_delta(data = '_data/rawdata.txt', niter = 1000, nwarmup = 0,ncore = 1)
L = bandit2arm_delta(data = '_data/rawdata.txt', niter = 1000, nwarmup = 0,ncore = 4)
L = bandit2arm_delta(data = '_data/rawdata.txt', niter = 1000, nwarmup = 10,ncore = 4)
library(rstan)
Sys.setenv(LOCAL_CPPFLAGS = '-march=native')
L = bandit2arm_delta(data = '_data/rawdata.txt', niter = 1000, nwarmup = 10,ncore = 4)
source('E:/teaching/BayesCog_2018/BayesCog_2018/06.reinforcement_learning/_scripts/reinforcement_learning_multi_parm_main.R')
rstan:::rstudio_stanc("_scripts/reinforcement_learning_sp_ms_model.stan")
load('_data/rl_sp_ss.RData')
sz <- dim(rl_ss)
nTrials <- sz[1]
head(rl_ss)
nTrials <- sz[1]
dataList <- list(nTrials=nTrials,
choice=rl_ss[,1],
reward=rl_ss[,2])
rstan_options(auto_write = TRUE)
options(mc.cores = 2)
# clear workspace
library(rstan)
library(ggplot2)
library(R.matlab)
options(mc.cores = 2)
modelFile <- '_scripts/reinforcement_learning_sp_ss_model.stan'
nIter     <- 2000
nChains   <- 4
nWarmup   <- floor(nIter/2)
nThin     <- 1
str(dataList)
rstan:::rstudio_stanc("_scripts/reinforcement_learning_sp_ss_model.stan")
cat("Estimating", modelFile, "model... \n")
startTime = Sys.time(); print(startTime)
cat("Calling", nChains, "simulations in Stan... \n")
fit_rl <- stan(modelFile,
data    = dataList,
chains  = nChains,
iter    = nIter,
warmup  = nWarmup,
thin    = nThin,
init    = "random",
seed    = 1450154626)
cat("Finishing", modelFile, "model simulation ... \n")
endTime = Sys.time(); print(endTime)
cat("It took",as.character.Date(endTime - startTime), "\n")
class(fit_rl)
str(fit_rl)
fit_rl$lr
fit_rl@model_name
fit_rl@model_pars
fit_rl@par_dims
fit_rl@mode
fit_rl@stan_args
fit_rl@stanmodel
fit_rl@date
fit_rl@.MISC
get_seed(fit_rl)
get_posterior_mean(fit_rl)
get_posterior_mean(fit_rl)[,5]
sample_lr = extract(fit_rl, pars= 'lr')
size(sample_lr)
dim(sample_lr)
legnth(sample_lr)
length(sample_lr)
length(sample_lr$lr)
sample_lr = extract(fit_rl, pars= 'lr')$lr
length(sample_lr)
hist(sample_lr)
pairs(fit_rl, pars= c('lr','tau'))
source('E:/teaching/BayesCog_standalone/BayesCog_Wien_2019/BayesCog_2019/06.reinforcement_learning/_scripts/HDIofMCMC.R')
HDIofMCMC(sample_lr)
source('E:/teaching/BayesCog_standalone/BayesCog_Wien_2019/BayesCog_2019/06.reinforcement_learning/_scripts/HDIofMCMC.R')
HDIofMCMC(sample_lr)
library(bayesplot)
# =============================================================================
#### Info ####
# =============================================================================
# simple reinforcement learning model
# single true parameters, true lr = 0.6, tau = 1.5, pRew = 0.7
#
# Lei Zhang
# lei.zhang@univie.ac.at
run_rl_sp <- function(multiSubj = FALSE) {
# =============================================================================
#### Construct Data ####
# =============================================================================
# clear workspace
library(rstan)
library(ggplot2)
library(R.matlab)
if (multiSubj==FALSE) {
load('_data/rl_sp_ss.RData')
sz <- dim(rl_ss)
nTrials <- sz[1]
dataList <- list(nTrials=nTrials,
choice=rl_ss[,1],
reward=rl_ss[,2])
} else {
load('_data/rl_sp_ms.RData')
sz <- dim(rl_ms)
nSubjects <- sz[1]
nTrials   <- sz[2]
dataList <- list(nSubjects=nSubjects,
nTrials=nTrials,
choice=rl_ms[,,1],
reward=rl_ms[,,2])
}
# =============================================================================
#### Running Stan ####
# =============================================================================
rstan_options(auto_write = TRUE)
options(mc.cores = 2)
if (multiSubj==FALSE) {
modelFile <- '_scripts/reinforcement_learning_sp_ss_model.stan'
} else {
modelFile <- '_scripts/reinforcement_learning_sp_ms_model.stan'
}
nIter     <- 2000
nChains   <- 4
nWarmup   <- floor(nIter/2)
nThin     <- 1
cat("Estimating", modelFile, "model... \n")
startTime = Sys.time(); print(startTime)
cat("Calling", nChains, "simulations in Stan... \n")
fit_rl <- stan(modelFile,
data    = dataList,
chains  = nChains,
iter    = nIter,
warmup  = nWarmup,
thin    = nThin,
init    = "random",
seed    = 1450154626)
cat("Finishing", modelFile, "model simulation ... \n")
endTime = Sys.time(); print(endTime)
cat("It took",as.character.Date(endTime - startTime), "\n")
# =============================================================================
#### Model Summary and Diagnostics ####
# =============================================================================
print(fit_rl)
plot_trace_excl_warm_up <- stan_trace(fit_rl, pars = c('lr','tau'), inc_warmup = F)
plot_dens <- stan_plot(fit_rl, pars=c('lr','tau'), show_density=T, fill_color = 'skyblue')
return(fit_rl)
}
source('E:/teaching/BayesCog_standalone/BayesCog_Wien_2019/BayesCog_2019/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
rm(list=ls(all=TRUE))
source('E:/teaching/BayesCog_standalone/BayesCog_Wien_2019/BayesCog_2019/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
rstan:::rstudio_stanc("_scripts/reinforcement_learning_sp_ms_model.stan")
rstan:::rstudio_stanc("_scripts/reinforcement_learning_sp_ms_model.stan")
source('E:/teaching/BayesCog_standalone/BayesCog_Wien_2019/BayesCog_2019/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
fit_sp_mp = run_rl_sp(multiSubj = T)
library(rstan)
lookup(dbinom)
run_rl_sp <- function(multiSubj = FALSE) {
# =============================================================================
#### Construct Data ####
# =============================================================================
# clear workspace
library(rstan)
library(ggplot2)
library(R.matlab)
if (multiSubj==FALSE) {
load('_data/rl_sp_ss.RData')
sz <- dim(rl_ss)
nTrials <- sz[1]
dataList <- list(nTrials=nTrials,
choice=rl_ss[,1],
reward=rl_ss[,2])
} else {
load('_data/rl_sp_ms.RData')
sz <- dim(rl_ms)
nSubjects <- sz[1]
nTrials   <- sz[2]
dataList <- list(nSubjects=nSubjects,
nTrials=nTrials,
choice=rl_ms[,,1],
reward=rl_ms[,,2])
}
# =============================================================================
#### Running Stan ####
# =============================================================================
rstan_options(auto_write = TRUE)
options(mc.cores = 2)
if (multiSubj==FALSE) {
modelFile <- '_scripts/reinforcement_learning_sp_ss_model.stan'
} else {
modelFile <- '_scripts/reinforcement_learning_sp_ms_model.stan'
}
nIter     <- 2000
nChains   <- 4
nWarmup   <- floor(nIter/2)
nThin     <- 1
cat("Estimating", modelFile, "model... \n")
startTime = Sys.time(); print(startTime)
cat("Calling", nChains, "simulations in Stan... \n")
fit_rl <- stan(modelFile,
data    = dataList,
chains  = nChains,
iter    = nIter,
warmup  = nWarmup,
thin    = nThin,
init    = "random",
seed    = 1450154626)
cat("Finishing", modelFile, "model simulation ... \n")
endTime = Sys.time(); print(endTime)
cat("It took",as.character.Date(endTime - startTime), "\n")
# =============================================================================
#### Model Summary and Diagnostics ####
# =============================================================================
print(fit_rl)
plot_trace_excl_warm_up <- stan_trace(fit_rl, pars = c('lr','tau'), inc_warmup = F)
plot_dens <- stan_plot(fit_rl, pars=c('lr','tau'), show_density=T, fill_color = 'skyblue')
return(fit_rl)
}
source('E:/teaching/BayesCog_Wien/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
rm(list=ls())
source('E:/teaching/BayesCog_Wien/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
load('_data/rl_sp_ss.RData')
sz <- dim(rl_ss)
nTrials <- sz[1]
dataList <- list(nTrials=nTrials,
choice=rl_ss[,1],
reward=rl_ss[,2])
source('E:/teaching/BayesCog_Wien/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
fit = run_rl_sp()
fit_rl = fit
print(fit_rl)
stan_trace(fit_rl, pars = c('lr','tau'), inc_warmup = F)
stan_trace(fit_rl, pars = c('lr','tau'), inc_warmup = F)
stan_plot(fit_rl, pars=c('lr','tau'), show_density=T, fill_color = 'skyblue')
rm(list=ls())
load('_data/rl_sp_ms.RData')
sz <- dim(rl_ms)
nSubjects <- sz[1]
nTrials   <- sz[2]
dataList <- list(nSubjects=nSubjects,
nTrials=nTrials,
choice=rl_ms[,,1],
reward=rl_ms[,,2])
rstan:::rstudio_stanc("_scripts/reinforcement_learning_sp_ms_model.stan")
source('E:/teaching/BayesCog_Wien/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
fit_rl_ms = run_rl_sp(TRUE)
rstan:::rstudio_stanc("_scripts/reinforcement_learning_mp_hrch_model.stan")
source('E:/teaching/BayesCog_Wien/06.reinforcement_learning/_scripts/reinforcement_learning_multi_parm_main.R')
source('E:/teaching/BayesCog_Wien/06.reinforcement_learning/_scripts/reinforcement_learning_multi_parm_main.R')
source('E:/teaching/BayesCog_Wien/06.reinforcement_learning/_scripts/reinforcement_learning_multi_parm_main.R')
f = run_rl_mp('hrch')
library(rstan)
library(ggplot2)
library(R.matlab)
load('_data/rl_sp_ss.RData')
sz <- dim(rl_ss)
nTrials <- sz[1]
dataList <- list(nTrials=nTrials,
choice=rl_ss[,1],
reward=rl_ss[,2])
str(dataList)
dataList$nTrials
dataList$choice
dataList$reward
str(dataList)
rstan:::rstudio_stanc("_scripts/my_first_RL.stan")
modelFile <- '_scripts/my_first_RL.stan'
nIter     <- 2000
nChains   <- 4
nWarmup   <- floor(nIter/2)
nThin     <- 1
cat("Estimating", modelFile, "model... \n")
startTime = Sys.time(); print(startTime)
cat("Calling", nChains, "simulations in Stan... \n")
fit_rl <- stan(modelFile,
data    = dataList,
chains  = nChains,
iter    = nIter,
warmup  = nWarmup,
thin    = nThin,
init    = "random",
seed    = 1450154626)
cat("Finishing", modelFile, "model simulation ... \n")
endTime = Sys.time(); print(endTime)
cat("It took",as.character.Date(endTime - startTime), "\n")
modelFile <- '_scripts/my_first_RL.stan'
modelFile <- '_scripts/my_first_RL.stan'
load('_data/rl_sp_ss.RData')
load('_data/rl_sp_ss.RData')
rm(list=ls())
source('E:/teaching/BayesCog_Wien/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
f = run_rl_sp()
source('E:/teaching/BayesCog_Wien/06.reinforcement_learning/_scripts/reinforcement_learning_single_parm_main.R')
getwd()
rstan:::rstudio_stanc("_scripts/my_RW.stan")
rstan:::rstudio_stanc("_scripts/my_RW.stan")
rstan:::rstudio_stanc("_scripts/my_RW.stan")
# normal()
# binomial, bernoulli
# categorical
# categorical
# normal()
# binomial, bernoulli
# categorical
library(rstan)
library(ggplot2)
library(R.matlab)
load('_data/rl_sp_ss.RData')
sz <- dim(rl_ss)
nTrials <- sz[1]
dataList <- list(nTrials=nTrials,
choice=rl_ss[,1],
reward=rl_ss[,2])
str(dataList)
modelFile <- '_scripts/my_RW.stan'
nIter     <- 2000
nChains   <- 4
nWarmup   <- floor(nIter/2)
nThin     <- 1
cat("Estimating", modelFile, "model... \n")
startTime = Sys.time(); print(startTime)
cat("Calling", nChains, "simulations in Stan... \n")
fit_rl <- stan(modelFile,
data    = dataList,
chains  = nChains,
iter    = nIter,
warmup  = nWarmup,
thin    = nThin,
init    = "random",
seed    = 1450154626)
cat("Finishing", modelFile, "model simulation ... \n")
endTime = Sys.time(); print(endTime)
cat("It took",as.character.Date(endTime - startTime), "\n")
stan_plot(fit_rl, pars=c('alpha','tau'), show_density=T, fill_color = 'skyblue')
? stan_plot
stan_plot(fit_rl, pars=c('alpha','tau'), show_density=T, fill_color = 'skyblue', ci_level = .9, outer_level =.99)
stan_plot(fit_rl, pars=c('alpha','tau'), show_density=T, fill_color = 'skyblue', ci_level = ., outer_level =.99)
stan_plot(fit_rl, pars=c('alpha','tau'), show_density=T, fill_color = 'skyblue', ci_level = .1, outer_level =.99)
